{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd5dbf6-c555-46e4-ac6c-2ebf29481e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\naish\\anaconda3\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: sounddevice in c:\\users\\naish\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from sounddevice) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\naish\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Requirement already satisfied: speechrecognition in c:\\users\\naish\\anaconda3\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from speechrecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\naish\\anaconda3\\lib\\site-packages (from speechrecognition) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2024.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\naish\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: spacy in c:\\users\\naish\\anaconda3\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\naish\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\naish\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\naish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pyaudio\n",
    "!pip install sounddevice\n",
    "!pip install speechrecognition\n",
    "!pip install scipy\n",
    "!pip install spacy\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf5108b-1034-4e39-9f03-882101b563be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8cbba7-a0df-4a72-8491-9440d892575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Amount                      Item\n",
      "0       50                   bananas\n",
      "1      100                 Starbucks\n",
      "2      200          electricity bill\n",
      "3      150                      fare\n",
      "4      300                    ticket\n",
      "..     ...                       ...\n",
      "260     75                      pens\n",
      "261   2000           tickets concert\n",
      "262    100                   mangoes\n",
      "263     50                     masks\n",
      "264    300  hours appointment doctor\n",
      "\n",
      "[265 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Trying with extracting nearest number to currency\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define transactions\n",
    "\n",
    "transactions=[\"Bought 50 rs of bananas\", \"Rs 100 at Starbucks\", \"Paid 200 rs for electricity bill\", \"Taxi fare of 150 rs\", \"Movie ticket for 300 rs\", \n",
    "\"Paid 75 bucks at the cafe\", \"Grocery shopping for 120 rupees\", \"Spent 500 rs on a new phone\", \"Cost 25 rupee for the book\", \"Spent 50.5 rs on fruits\",\n",
    "\"I spent Rupees 100 on water\", \"I spent 200 rupees on groceries\", \"I bought a movie ticket for 500 rupees\", \"Spent 300 on bus fare\", \n",
    "\"Paid 1000 rupees for a doctor visit\", \"Bought new furniture for 1500 rupees\", \"Spent 600 on books\", \"Paid 700 for electricity bill\", \n",
    "\"Spent 1200 rupees on a concert\", \"I spent 250 on fruits\", \"Paid 400 for a taxi ride\", \"I visited the doctor and spent 1000rs\", \n",
    "\"Spent 220 rupees on transportation\", \"Spent 230 rupees on entertainment\", \"Spent 240 rupees on household\", \"Spent 250 rupees on shopping\", \n",
    "\"Spent 260 rupees on health\", \"Spent 270 rupees on education\", \"Spent 280 rupees on gift\", \"Spent 290 rupees on others\", \"Spent 300 rupees on food\",\n",
    "\"Spent 310 rupees on social_life\", \"Spent 3460 rupees on health\", \"Spent 3470 rupees on education\", \"Spent 3480 rupees on gift\", \n",
    "\"Spent 3490 rupees on others\", \"Spent 450 rupees on dinner with friends.\", \"Bought a souvenir for 200 rupees.\", \"Paid 75 rs for a postcard.\",\n",
    "\"Spent 300 rupees on a photo frame.\", \"Bought a wallet for 500 rupees.\", \"Spent 120 rupees on face wash.\", \"Paid 40 rs for a bookmark.\", \n",
    "\"Bought a cup of coffee for 150 rupees.\", \"Paid 350 rupees for a doctor's appointment.\", \"I spent 500 on a nice lunch.\", \n",
    "\"Bought new headphones for 1000 rupees.\", \"Cost 75 rupees for the magazine.\", \"Paid 200 for parking fees.\", \"Spent 60 rupees on a bottle of water.\",\n",
    "\"Taxi fare of 200 rupees.\", \"Bought groceries worth 500 rupees.\", \"Paid 100 rupees for movie snacks.\", \"Spent 120 rupees on stationery.\",\n",
    "\"Paid 300 rs for a haircut.\", \"Spent 200 rupees on a train ticket.\", \"Bought snacks for 100 rupees.\", \"Paid 75 rs for coffee.\",\n",
    "\"Spent 50 rupees on a juice.\", \"Paid 600 rs for a fitness class.\", \"Bought clothes worth 1000 rupees.\", \"Spent 200 rupees on a bus fare.\",\n",
    "\"Cost 150 rupees at the bakery.\", \"Spent 40 rupees on gum.\", \"Paid 1200 rs for the dentist.\", \"Bought a new bag for 700 rupees.\",\n",
    "\"Spent 100 rs on phone recharge.\", \"Paid 300 rupees for flowers.\", \"Spent 500 rs on a family dinner.\", \"Paid 250 for a museum ticket.\", \n",
    "\"Bought books worth 350 rupees.\", \"Spent 80 rupees on tea.\", \"Cost 900 rupees at the optician.\", \"Paid 1000 rs for sports equipment.\", \n",
    "\"Spent 500 rupees on clothes.\", \"Taxi fare of 350 rs.\", \"Spent 50 rupees on stationery.\", \"Paid 60 rs for an ice cream.\", \n",
    "\"Spent 2000 rupees on a new pair of shoes.\", \"Bought a cake for 500 rupees.\", \"Paid 1000 rs for the hotel stay.\", \"Spent 150 rupees on a meal.\", \n",
    "\"Bought tickets worth 800 rupees.\", \"Spent 350 on a concert ticket.\", \"Paid 400 rupees for medical supplies.\", \"Spent 100 rs on a movie rental.\", \n",
    "\"Cost 75 rs for entry fees.\", \"Bought a hat for 250 rupees.\", \"Spent 180 rupees on phone accessories.\", \"Paid 500 rs for a cooking class.\", \n",
    "\"Spent 120 rupees on a gift.\", \"Bought fruit worth 75 rupees.\", \"Spent 650 rs on a dress.\", \"Paid 2500 rupees on an online course.\", \n",
    "\"Spent 300 rupees on lunch.\", \"Taxi fare of 100 rs.\", \"Spent 200 rupees on a pedicure.\", \"Paid 350 rs for a game.\", \"Bought groceries for 250 rupees.\",\n",
    "\"Paid 125 rs at the coffee shop.\", \"Spent 90 rupees on a snack.\", \"Bought veggies worth 200 rupees.\", \"Spent 1200 rs on a fitness tracker.\", \n",
    "\"Paid 45 rs for a candy bar.\", \"Taxi fare of 150 rs.\", \"Spent 300 rupees on groceries.\", \"Bought a magazine for 50 rs.\", \n",
    "\"Paid 75 rupees for the library fee.\", \"Spent 250 rupees on a movie ticket.\", \"Spent 100 rupees on a cold drink.\", \"Paid 700 rupees for car service.\",\n",
    "\"Bought accessories for 400 rs.\", \"Spent 60 rupees on popcorn.\", \"Paid 500 rupees for a phone case.\", \"Bought a t-shirt for 300 rupees.\", \n",
    "\"Paid 80 rs for a notebook.\", \"Spent 150 rupees on stationery.\", \"Paid 450 rs at the dentist.\", \"Bought flowers worth 100 rupees.\",\n",
    "\"Spent 1200 rupees on groceries.\", \"Taxi fare of 90 rs.\", \"Spent 200 rs on a cab ride.\", \"Paid 120 rupees at the coffee shop.\", \n",
    "\"Bought a scarf for 200 rupees.\", \"Spent 75 rs on street food.\", \"Paid 300 rupees for gym membership.\", \"Spent 2500 rs on a hotel room.\", \n",
    "\"Bought an umbrella for 150 rupees.\", \"Spent 100 rs on a drink.\", \"Paid 500 rs for a city tour.\", \"Bought a novel for 350 rupees.\",\n",
    "\"Spent 120 rupees on juice.\", \"Paid 400 rupees for car wash.\", \"Bought a jacket worth 800 rs.\", \"Spent 150 rupees on a meal.\", \n",
    "\"Paid 90 rupees for a newspaper.\", \"Spent 200 rupees on dinner.\", \"Bought a bag for 1000 rupees.\", \"Paid 70 rupees for a bookmark.\", \n",
    "\"Spent 350 rs on laundry.\", \"Bought cosmetics for 200 rupees.\", \"Paid 50 rupees for a pen.\", \"Spent 1200 rupees on a concert ticket.\",\n",
    "\"Spent 180 rupees on stationery.\", \"Bought a sandwich for 50 rupees\", \"Paid 200 rupees for gym fees\", \"Spent 150 rupees on a coffee\", \n",
    "\"Bought a book for 300 rupees\", \"Paid 100 rupees for snacks\", \"Spent 400 rupees on a shirt\", \"Taxi fare of 120 rupees\", \"Bought a pen for 20 rupees\",\n",
    "\"Spent 500 rupees on a birthday gift\", \"Paid 60 rupees for a bottle of water\", \"Spent 150 rupees on dinner\", \"Bought groceries for 700 rupees\", \n",
    "\"Spent 80 rupees on a magazine\", \"Paid 1000 rupees for a health check-up\", \"Bought a concert ticket for 900 rupees\", \"Spent 50 rupees on stationery\",\n",
    "\"Paid 75 rupees for coffee at Starbucks\", \"Spent 60 rupees on a snack\", \"Bought a scarf for 200 rupees\", \"Paid 400 rupees for lunch with friends\",\n",
    "\"Spent 30 rupees on gum\", \"Bought a new water bottle for 100 rupees\", \"Spent 350 rupees on school supplies\", \"Paid 300 rupees for a taxi ride\",\n",
    "\"Bought a phone case for 150 rupees\", \"Spent 200 rupees on a bus ticket\", \"Paid 80 rupees for a notepad\", \"Bought a pack of biscuits for 50 rupees\",\n",
    "\"Spent 120 rupees on movie snacks\", \"Paid 600 rupees for a cooking class\", \"Spent 400 rupees on a family meal\", \"Bought a new wallet for 250 rupees\", \n",
    "\"Paid 45 rupees for a soda\", \"Spent 350 rupees on a museum ticket\", \"Bought a fruit basket for 150 rupees\", \"Spent 220 rupees on a taxi ride\", \n",
    "\"Paid 75 rupees for an ice cream\", \"Spent 100 rupees on chocolates\", \"Bought a novel for 250 rupees\", \"Paid 2000 rupees for a weekend stay\", \n",
    "\"Spent 90 rupees on a fruit juice\", \"Bought groceries for 600 rupees\", \"Spent 800 rupees on a new shirt\", \"Paid 70 rupees for a tea\", \n",
    "\"Bought a lunchbox for 200 rupees\", \"Spent 50 rupees on a cold drink\", \"Paid 400 rupees for flowers\", \"Bought a pair of sunglasses for 300 rupees\", \n",
    "\"Spent 75 rupees on parking fees\", \"Paid 100 rupees for movie rental\", \"Bought a coffee for 120 rupees\", \"Spent 600 rupees on groceries\", \n",
    "\"Paid 300 rupees for car wash\", \"Bought a cake for 250 rupees\", \"Spent 400 rupees on a fitness tracker\", \"Paid 1500 rupees for gym membership\", \n",
    "\"Bought a novel for 350 rupees\", \"Spent 100 rupees on a drink\", \"Paid 50 rupees for candy\", \"Bought a jacket for 700 rupees\", \"Spent 500 rupees on a family dinner\", \n",
    "\"Paid 120 rupees for street food\", \"Bought cosmetics for 300 rupees\", \"Spent 150 rupees on a juice\", \"Paid 700 rupees for doctor’s appointment\", \n",
    "\"Bought a keychain for 50 rupees\", \"Spent 60 rupees on popcorn\", \"Paid 300 rupees for a movie\", \"Bought a new pair of shoes for 1200 rupees\",\n",
    "\"Spent 500 rupees on groceries\", \"Paid 100 rupees for a bus pass\", \"Bought a souvenir for 100 rupees\", \"Spent 200 rupees on dinner with friends\",\n",
    "\"Paid 90 rupees for a newspaper\", \"Bought a bottle of water for 20 rupees\", \"Spent 300 rupees on phone accessories\", \n",
    "\"Paid 600 rupees for a cooking course\", \"Bought a birthday gift for 400 rupees\", \"Spent 500 rupees on a backpack\", \"Paid 200 rupees for a train ticket\",\n",
    "\"Bought a magazine for 60 rupees\", \"Spent 40 rupees on stationery\", \"Paid 100 rupees for snacks\", \"Bought groceries worth 750 rupees\", \n",
    "\"Spent 1500 rupees on a weekend getaway\", \"Paid 250 rupees for entry fees\", \"Bought an umbrella for 300 rupees\",\n",
    "\"Spent 1000 rupees on a gym subscription\", \"Paid 30 rupees for a bookmark\", \"Bought a new bag for 900 rupees\", \"Spent 600 rupees on clothes\", \n",
    "\"Paid 200 rupees for a manicure\", \"Bought a movie ticket for 400 rupees\", \"Spent 60 rupees on coffee\", \"Paid 150 rupees for a magazine\", \n",
    "\"Bought a birthday card for 20 rupees\", \"Spent 300 rupees on a scarf\", \"Paid 80 rupees for a cold drink\", \"Bought a fitness band for 700 rupees\",\n",
    "\"Spent 50 rupees on a snack\", \"Bought 5 apples for 150 rs\", \"Paid 10 bucks for 200 grams of coffee\", \"I spent 8 hours working on a 400 rs project\", \n",
    "    \"Got 2 pens and a notebook for 50 rs\", \"Purchased 6 oranges for 30 rupees\", \"I got 3 pairs of socks for 120 rs\",\n",
    "    \"Bought 4 tickets for 800 rupees\", \"Received 20 items, paid 300 bucks total\", \"Spent 5 days at a hotel for 2000 rupees\",\n",
    "    \"Bought 3 books for 450 rs\", \"I bought 2 packets of chips for 20 rupees each\", \"Got 10 candies and paid 50 rs for all\", \n",
    "    \"Bought 12 eggs for 60 rs\", \"Purchased 3 packs of pasta for 90 bucks\", \"Got 7 bananas for 35 rupees\", \n",
    "    \"Bought 5 bottles of water for 25 rs each\", \"I bought 15 pens for 75 rs\", \"Paid 2000 rs for 4 tickets to the concert\", \n",
    "    \"Bought 8 mangoes for 100 rupees\", \"Purchased 10 masks for 50 rs\",\"For a 3 hours appointment at doctor, paid 300 rs\" ]\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the improved extraction function\n",
    "def extract_amount_item(transaction):\n",
    "    # Tokenize the transaction text\n",
    "    tokens = nltk.word_tokenize(transaction)\n",
    "    \n",
    "    # POS tagging\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Compile a list of common currency words\n",
    "    currency_terms = {\"rs\", \"rupees\", \"bucks\", \"dollars\", \"pounds\", \"cost\", \"rupee\", \"lakh\", \"crore\", \"million\"}\n",
    "    \n",
    "    # Initialize amount as \"Unknown\" and a flag for currency presence\n",
    "    amount = \"Unknown\"\n",
    "    currency_found = False\n",
    "    \n",
    "    # Find the closest number to the currency term if present\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.lower() in currency_terms:\n",
    "            currency_found = True\n",
    "            # Check for a number before or after the currency term\n",
    "            if i > 0 and re.match(r'\\d+(\\.\\d+)?', tokens[i-1]):  # Check previous token\n",
    "                amount = tokens[i-1]\n",
    "            elif i < len(tokens) - 1 and re.match(r'\\d+(\\.\\d+)?', tokens[i+1]):  # Check next token\n",
    "                amount = tokens[i+1]\n",
    "            break  # Stop after finding the first currency term\n",
    "\n",
    "    # If no currency term found, look for any number in the sentence\n",
    "    if not currency_found:\n",
    "        for token in tokens:\n",
    "            if re.match(r'\\d+(\\.\\d+)?', token):  # Find any number\n",
    "                amount = token\n",
    "                break  # Stop after finding the first number\n",
    "\n",
    "    # Extract nouns as potential items, filtering out currency terms\n",
    "    item_tokens = []\n",
    "    for word, tag in pos_tags:\n",
    "        # Collect nouns (NN, NNS) that are not currency terms\n",
    "        if tag in ['NN', 'NNS'] and word.lower() not in currency_terms:\n",
    "            item_tokens.append(word)\n",
    "    \n",
    "    # Join tokens to form the item name, if available\n",
    "    item = \" \".join(item_tokens) if item_tokens else \"Unknown\"\n",
    "    \n",
    "    return amount.strip(), item.strip()\n",
    "\n",
    "# Apply the refined extraction to all transactions\n",
    "extracted_data = [extract_amount_item(transaction) for transaction in transactions]\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame(extracted_data, columns=['Amount', 'Item'])\n",
    "\n",
    "# Print the result\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e81e7ea-81c8-487b-8282-4de05b6b5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Define expanded categories with additional relevant synsets in WordNet\n",
    "hypernym_categories = {\n",
    "    'food': [\n",
    "        wn.synset('food.n.01'), wn.synset('meal.n.01'), wn.synset('snack.n.01'), wn.synset('drink.n.01'),\n",
    "        wn.synset('dish.n.01'), wn.synset('fruit.n.01'), wn.synset('vegetable.n.01'), wn.synset('dessert.n.01'),\n",
    "        wn.synset('grocery.n.01'), wn.synset('produce.n.01'), wn.synset('beverage.n.01'), wn.synset('cooking.n.01'),\n",
    "        wn.synset('eating.n.01'), wn.synset('cuisine.n.01'), wn.synset('dairy_product.n.01'), wn.synset('meat.n.01'),\n",
    "        wn.synset('seafood.n.01'), wn.synset('spice.n.01'), wn.synset('ingredient.n.01')\n",
    "    ],\n",
    "    'social_life': [\n",
    "        wn.synset('recreation.n.01'), wn.synset('celebration.n.01'), wn.synset('outing.n.01'), wn.synset('party.n.01'),\n",
    "        wn.synset('dancing.n.01'), wn.synset('social_event.n.01'), wn.synset('entertainment.n.01'), wn.synset('concert.n.01'),\n",
    "        wn.synset('movie.n.01'), wn.synset('gathering.n.01'), wn.synset('festival.n.01'), wn.synset('show.n.01'),\n",
    "        wn.synset('nightclub.n.01'), wn.synset('bar.n.01'), wn.synset('pub.n.01'), wn.synset('celebration.n.01')\n",
    "    ],\n",
    "    'transportation': [\n",
    "        wn.synset('vehicle.n.01'), wn.synset('transportation.n.01'), wn.synset('public_transport.n.01'), wn.synset('taxi.n.01'),\n",
    "        wn.synset('airplane.n.01'), wn.synset('car.n.01'), wn.synset('train.n.01'), wn.synset('bus.n.01'),\n",
    "        wn.synset('fare.n.01'), wn.synset('subway.n.01'), wn.synset('railway.n.01'), wn.synset('transport.n.01'),\n",
    "        wn.synset('commute.n.01'), wn.synset('travel.n.01'), wn.synset('motor_vehicle.n.01'), wn.synset('bicycle.n.01'),\n",
    "        wn.synset('ticket.n.01'), wn.synset('road.n.01')\n",
    "    ],\n",
    "    'entertainment': [\n",
    "        wn.synset('culture.n.01'), wn.synset('art.n.01'), wn.synset('entertainment.n.01'), wn.synset('concert.n.01'),\n",
    "        wn.synset('museum.n.01'), wn.synset('movie.n.01'), wn.synset('game.n.01'), wn.synset('sport.n.01'),\n",
    "        wn.synset('amusement.n.01'), wn.synset('theater.n.01'), wn.synset('exhibition.n.01'), wn.synset('show.n.01'),\n",
    "        wn.synset('play.n.01'), wn.synset('performance.n.01'), wn.synset('event.n.01'), wn.synset('hobby.n.01')\n",
    "    ],\n",
    "    'household': [\n",
    "        wn.synset('household.n.01'), wn.synset('furniture.n.01'), wn.synset('appliance.n.01'), wn.synset('utility.n.01'),\n",
    "        wn.synset('cleaning.n.01'), wn.synset('kitchenware.n.01'), wn.synset('decoration.n.01'), wn.synset('bedding.n.01'),\n",
    "        wn.synset('laundry.n.01'), wn.synset('repair.n.01'), wn.synset('gardening.n.01'), wn.synset('maintenance.n.01'),\n",
    "        wn.synset('utensil.n.01'), wn.synset('fixture.n.01'), wn.synset('housework.n.01')\n",
    "    ],\n",
    "    'shopping': [\n",
    "        wn.synset('clothing.n.01'), wn.synset('footwear.n.01'), wn.synset('accessory.n.01'), wn.synset('outerwear.n.01'),\n",
    "        wn.synset('toiletry.n.01'), wn.synset('cosmetic.n.01'), wn.synset('jewelry.n.01'), wn.synset('apparel.n.01'),\n",
    "        wn.synset('bag.n.01'), wn.synset('watch.n.01'), wn.synset('fashion.n.01'), wn.synset('retail.n.01'),\n",
    "        wn.synset('boutique.n.01'), wn.synset('department_store.n.01'), wn.synset('shopping.n.01')\n",
    "    ],\n",
    "    'health': [\n",
    "        wn.synset('health.n.01'), wn.synset('medicine.n.01'), wn.synset('therapy.n.01'), wn.synset('fitness.n.01'),\n",
    "        wn.synset('exercise.n.01'), wn.synset('training.n.01'), wn.synset('meditation.n.01'), wn.synset('nutrition.n.01'),\n",
    "        wn.synset('doctor.n.01'), wn.synset('hospital.n.01'), wn.synset('wellness.n.01'), wn.synset('pharmacy.n.01'),\n",
    "        wn.synset('clinic.n.01'), wn.synset('dentist.n.01'), wn.synset('treatment.n.01'), wn.synset('nurse.n.01'),\n",
    "        wn.synset('diet.n.01')\n",
    "    ],\n",
    "    'education': [\n",
    "        wn.synset('education.n.01'), wn.synset('schooling.n.01'), wn.synset('book.n.01'), wn.synset('course.n.01'),\n",
    "        wn.synset('lecture.n.01'), wn.synset('research.n.01'), wn.synset('workshop.n.01'), wn.synset('library.n.01'),\n",
    "        wn.synset('stationery.n.01'), wn.synset('tuition.n.01'), wn.synset('student.n.01'), wn.synset('class.n.01'),\n",
    "        wn.synset('teacher.n.01'), wn.synset('exam.n.01'), wn.synset('assignment.n.01'), wn.synset('university.n.01')\n",
    "    ],\n",
    "    'gift': [\n",
    "        wn.synset('gift.n.01'), wn.synset('present.n.01'), wn.synset('souvenir.n.01'), wn.synset('donation.n.01'),\n",
    "        wn.synset('offering.n.01'), wn.synset('keepsake.n.01'), wn.synset('award.n.01'), wn.synset('memento.n.01'),\n",
    "        wn.synset('prize.n.01'), wn.synset('trophy.n.01'), wn.synset('celebration.n.01'), wn.synset('token.n.01')\n",
    "    ],\n",
    "    'others': [\n",
    "        wn.synset('artifact.n.01'), wn.synset('object.n.01'), wn.synset('thing.n.01'), wn.synset('item.n.01'),\n",
    "        wn.synset('material.n.01'), wn.synset('equipment.n.01'), wn.synset('supply.n.01'), wn.synset('instrumentality.n.01'),\n",
    "        wn.synset('device.n.01'), wn.synset('commodity.n.01'), wn.synset('resource.n.01'), wn.synset('tool.n.01')\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Flatten synsets for each category to enable direct comparison\n",
    "flattened_hypernym_categories = {cat: synsets for cat, synsets in hypernym_categories.items()}\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "direct_mappings = {\n",
    "    'bananas': 'food', 'starbucks': 'food', 'electricity bill': 'household', 'fare': 'transportation', \n",
    "    'ticket': 'entertainment', 'cafe': 'food', 'shopping': 'shopping', 'phone': 'entertainment', \n",
    "    'rupee book': 'education', 'water': 'food', 'groceries': 'food', 'movie ticket': 'entertainment',\n",
    "    'bus fare': 'transportation', 'doctor visit': 'health', 'furniture': 'household', 'books': 'education', \n",
    "    'electricity': 'household', 'concert': 'social_life', 'taxi ride': 'transportation'\n",
    "}\n",
    "\n",
    "# Helper function to check if any synset in a hypernym path matches the target synsets for a category\n",
    "def is_hypernym_in_path(synset, target_hypernyms):\n",
    "    hypernym_paths = synset.hypernym_paths()  # Get all hypernym paths\n",
    "    for path in hypernym_paths:\n",
    "        for ancestor in path:\n",
    "            if ancestor in target_hypernyms:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Get category by hypernym path and semantic similarity\n",
    "def get_category(item):\n",
    "    # Take only the first word if the item has multiple words\n",
    "    first_word = item.split()[0]\n",
    "    \n",
    "    # Normalize and lemmatize the first word\n",
    "    lemmatized_item = lemmatizer.lemmatize(first_word.lower())\n",
    "    \n",
    "    # Check direct mappings first\n",
    "    if lemmatized_item in direct_mappings:\n",
    "        return direct_mappings[lemmatized_item]\n",
    "    \n",
    "    # Get synsets for the item as a noun\n",
    "    item_synsets = wn.synsets(lemmatized_item, pos=wn.NOUN)\n",
    "    for synset in item_synsets:\n",
    "        # Check if any synset in the item's hypernym path matches a category\n",
    "        for category, target_hypernyms in hypernym_categories.items():\n",
    "            if is_hypernym_in_path(synset, target_hypernyms):\n",
    "                return category\n",
    "\n",
    "    # As a last resort, use semantic similarity to find the closest category\n",
    "    best_category = 'others'\n",
    "    max_similarity = 0\n",
    "    for synset in item_synsets:\n",
    "        for category, target_hypernyms in hypernym_categories.items():\n",
    "            for target_synset in target_hypernyms:\n",
    "                similarity = synset.path_similarity(target_synset)\n",
    "                if similarity and similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_category = category\n",
    "    return best_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fc86b3-a0ea-4373-9800-770e5c087685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'] = df['Item'].apply(get_category)\n",
    "df\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('path_to_your_file2.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a45bf6d8-34f2-40c3-bcf1-3c5a74d82d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "RATE = 16000  # Sample rate\n",
    "CHUNK = 1024  # Number of frames per buffer\n",
    "\n",
    "def is_silent(data, threshold=500):\n",
    "    \"\"\"Returns 'True' if below the 'silent' threshold\"\"\"\n",
    "    return np.abs(np.frombuffer(data, dtype=np.int16)).max() < threshold\n",
    "\n",
    "def record_audio():\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    audio_data = io.BytesIO()\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Listening...\")\n",
    "    silence_start = None\n",
    "    audio_chunks = []\n",
    "    \n",
    "    while True:\n",
    "        data = stream.read(CHUNK)\n",
    "        audio_chunks.append(data)\n",
    "        \n",
    "        if is_silent(data):\n",
    "            if silence_start is None:\n",
    "                silence_start = time.time()\n",
    "            elif time.time() - silence_start > 3:\n",
    "                break\n",
    "        else:\n",
    "            silence_start = None\n",
    "    \n",
    "    print(\"Recording complete\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    audio_data.write(b''.join(audio_chunks))\n",
    "    audio_data.seek(0)\n",
    "    return audio_data, recognizer\n",
    "\n",
    "def speech_to_text(audio_data, recognizer):\n",
    "    audio = sr.AudioData(audio_data.read(), RATE, 2)\n",
    "    text = recognizer.recognize_google(audio)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "35e60cab-8364-4d80-b453-cb22c81e5c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recording complete\n",
      "Recognized Text: I got two packets milk for Rs 200\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "audio_data, recognizer = record_audio()\n",
    "    \n",
    "# Convert speech to text\n",
    "text = speech_to_text(audio_data, recognizer)\n",
    "print(\"Recognized Text:\", text)\n",
    "amt, item = extract_amount_item(text)\n",
    "category = get_category(item)\n",
    "timestamp = datetime.now()\n",
    "type='expense'\n",
    "importance='Not Important'\n",
    "\n",
    "#     # Create a new DataFrame for the new row\n",
    "# new_row_df = pd.DataFrame([[amt, item, category, timestamp,type, importance]], columns=['Amount', 'Item', 'Category', 'Timestamp', 'Type', 'Importance'])\n",
    "\n",
    "#     # Concatenate the new row to the existing DataFrame\n",
    "# df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "#     # Display the DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "95d8ecf4-d343-41ec-85cf-d867882bf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d701e9e7-fd38-4568-911c-a1d89b5e3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn=sqlite3.connect(\"categorised_transaction.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a631f16b-929d-456b-bfe4-b0722c162b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1b177dba340>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('''\n",
    "create table if not exists transactions(\n",
    "transaction_id INTEGER AUTO_INCREMENT PRIMARY KEY,\n",
    "Timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "category VARCHAR(30),\n",
    "item VARCHAR(50),\n",
    "amount INT,\n",
    "type Varchar(10),\n",
    "importance Varchar(20)\n",
    ")''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a349ae3a-d355-41a1-98e5-09291d09f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d4ca4923-4f78-4254-a42a-cca544d000c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transaction_entry(amt, item, category, timestamp, type, importance):\n",
    "    conn.execute(\"insert into transactions (amount, item, category, Timestamp, type, importance) VALUES(?,?,?,?,?,?)\",(amt, item, category, timestamp, type, importance))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3b32858-5651-4dbe-acbb-eb99eaac2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_entry(amt, item, category, timestamp,type, importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "68f2f98d-a688-481e-ac66-e2c23d075d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, '2022-01-05 03:26:21.000000', 'food', 'To kumara', 150, 'Expense', 'Not Important'), (None, '2022-01-06 11:27:47.000000', 'entertainment', 'museum ticket', 250, 'Expense', 'Not Important'), (None, '2022-01-07 12:19:50.000000', 'transportation', 'car wash', 400, 'Expense', 'Not Important'), (None, '2022-01-14 04:04:05.000000', 'others', 'notepad', 80, 'Expense', 'Not Important'), (None, '2022-01-15 11:00:40.000000', 'others', 'cup coffee', 150, 'Expense', 'Not Important'), (None, '2022-01-16 09:04:29.000000', 'food', 'chocolates', 100, 'Expense', 'Not Important'), (None, '2022-01-19 15:55:36.000000', 'others', 'Salary from dad', 5000, 'Income', 'Not Important'), (None, '2022-01-25 22:40:47.000000', 'food', 'Snacks', 250, 'Expense', 'Not Important'), (None, '2022-01-29 16:42:47.000000', 'food', 'Pizza', 301.75, 'Expense', 'Not Important'), (None, '2022-01-30 05:33:51.000000', 'others', 'To vishnu', 100, 'Expense', 'Not Important'), (None, '2022-02-01 07:52:30.000000', 'food', None, 25, 'Expense', 'Not Important'), (None, '2022-02-01 10:12:40.000000', 'food', 'lunch friends', 400, 'Expense', 'Not Important'), (None, '2022-02-01 10:30:47.000000', 'health', 'health', 3460, 'Expense', 'Not Important'), (None, '2022-02-05 23:11:50.000000', 'food', 'drink', 100, 'Expense', 'Not Important'), (None, '2022-02-08 04:36:24.000000', 'food', 'snack', 90, 'Expense', 'Not Important'), (None, '2022-02-09 22:53:17.000000', 'food', 'Coconut water with stu', 50, 'Expense', 'Important'), (None, '2022-02-11 12:04:12.000000', 'food', 'groceries', 500, 'Expense', 'Not Important'), (None, '2022-02-14 12:57:30.000000', 'others', 'bananas', 50, 'Expense', 'Not Important'), (None, '2022-02-14 22:26:24.000000', 'others', 'Gundan + prasanna', 340, 'Income', 'Not Important'), (None, '2022-02-14 23:39:46.000000', 'food', 'drink', 80, 'Expense', 'Not Important'), (None, '2022-02-16 05:52:05.000000', 'food', 'Dinner', 50, 'Expense', 'Not Important'), (None, '2022-02-17 08:22:39.000000', 'others', 'From kumara', 200, 'Income', 'Not Important'), (None, '2022-02-18 02:19:03.000000', 'food', 'Horlicks + kolakattai', 25, 'Expense', 'Not Important'), (None, '2022-02-18 16:38:07.000000', 'food', 'snacks', 100, 'Expense', 'Not Important'), (None, '2022-02-18 18:31:42.000000', 'others', 'supplies', 400, 'Expense', 'Not Important'), (None, '2022-02-18 18:41:10.000000', 'food', 'dinner friends', 450, 'Expense', 'Not Important'), (None, '2022-02-19 17:18:50.000000', 'health', 'fitness band', 700, 'Expense', 'Not Important'), (None, '2022-02-19 23:35:00.000000', 'household', 'electricity bill', 200, 'Expense', 'Important'), (None, '2022-02-23 05:26:00.000000', 'social life', 'Beer', 150, 'Expense', 'Not Important'), (None, '2022-02-24 04:05:58.000000', 'food', 'water', 100, 'Expense', 'Important'), (None, '2022-02-25 05:30:46.000000', 'food', 'Dinner with barath', 200, 'Expense', 'Not Important'), (None, '2022-02-27 04:05:42.000000', 'food', 'Snacks', 20, 'Expense', 'Not Important'), (None, '2022-02-28 00:18:39.000000', 'shopping', 'clothes', 500, 'Expense', 'Not Important'), (None, '2022-02-28 13:22:16.000000', 'food', 'Lunch pongal', 1530, 'Expense', 'Not Important'), (None, '2022-03-01 22:21:03.000000', 'household', 'Rent', 4580, 'Expense', 'Important'), (None, '2022-03-04 23:47:48.000000', 'entertainment', 'pedicure', 200, 'Expense', 'Not Important'), (None, '2022-03-06 03:47:29.000000', 'health', 'health check-up', 1000, 'Expense', 'Not Important'), (None, '2022-03-06 13:32:08.000000', 'others', 'cake', 500, 'Expense', 'Not Important'), (None, '2022-03-08 18:24:39.000000', 'others', 'newspaper', 90, 'Expense', 'Not Important'), (None, '2022-03-10 04:47:56.000000', 'food', 'Dinner with roommate', 877.81, 'Expense', 'Not Important'), (None, '2022-03-10 12:16:20.000000', 'household', 'Rent', 4800, 'Expense', 'Important'), (None, '2022-03-12 02:47:00.000000', 'others', 'From abi', 300, 'Income', 'Not Important'), (None, '2022-03-16 05:31:48.000000', 'others', 'grams coffee', 10, 'Expense', 'Not Important'), (None, '2022-03-16 05:55:45.000000', 'others', 'From dad', 1000, 'Income', 'Not Important'), (None, '2022-03-21 15:40:07.000000', 'entertainment', 'phone case', 150, 'Expense', 'Important'), (None, '2022-03-21 21:17:54.000000', 'food', 'Zinger box meal', 279, 'Expense', 'Not Important'), (None, '2022-03-25 16:36:24.000000', 'social life', 'weekend getaway', 1500, 'Expense', 'Not Important'), (None, '2022-04-02 07:45:49.000000', 'others', 'From barath', 201, 'Income', 'Not Important'), (None, '2022-04-03 08:22:48.000000', 'social life', 'concert ticket', 350, 'Expense', 'Not Important'), (None, '2022-04-06 19:06:25.000000', 'household', 'electricity bill', 700, 'Expense', 'Important'), (None, '2022-04-07 09:50:26.000000', 'others', 'To abijith', 200, 'Expense', 'Not Important'), (None, '2022-04-08 13:49:47.000000', 'others', 'cake', 250, 'Expense', 'Not Important'), (None, '2022-04-10 06:50:10.000000', 'food', 'Lunch with gowdham', 535.3, 'Expense', 'Not Important'), (None, '2022-04-20 20:50:28.000000', 'health', 'fitness tracker', 400, 'Expense', 'Not Important'), (None, '2022-04-22 20:33:15.000000', 'others', 'novel', 350, 'Expense', 'Not Important'), (None, '2022-04-23 04:08:55.000000', 'food', 'Zomato', 269.4, 'Expense', 'Not Important'), (None, '2022-05-01 11:40:36.000000', 'food', '5 star', 15, 'Expense', 'Not Important'), (None, '2022-05-05 03:15:59.000000', 'others', 'bottle water', 60, 'Expense', 'Important'), (None, '2022-05-05 13:04:22.000000', 'food', 'coffee shop', 125, 'Expense', 'Not Important'), (None, '2022-05-10 06:57:29.000000', 'shopping', 'scarf', 300, 'Expense', 'Not Important'), (None, '2022-05-12 00:06:54.000000', 'others', 'face wash', 120, 'Expense', 'Not Important'), (None, '2022-05-13 03:22:17.000000', 'others', 'cab ride', 200, 'Expense', 'Not Important'), (None, '2022-05-13 20:23:07.000000', 'food', 'Milk with bharath', 25, 'Expense', 'Not Important'), (None, '2022-05-14 08:13:49.000000', 'entertainment', 'entry fees', 250, 'Expense', 'Not Important'), (None, '2022-05-15 06:22:20.000000', 'food', 'Good soup', 50, 'Expense', 'Not Important'), (None, '2022-05-16 23:06:54.000000', 'transportation', 'Vnr to apk', 50, 'Expense', 'Not Important'), (None, '2022-05-17 01:18:03.000000', 'others', 'Gave to gowdham', 50, 'Expense', 'Not Important'), (None, '2022-05-19 19:37:29.000000', 'food', 'Lunch with company', 262, 'Expense', 'Not Important'), (None, '2022-05-20 13:18:24.000000', 'others', 'Lended money', 400, 'Income', 'Not Important'), (None, '2022-05-30 14:47:06.000000', 'shopping', 'scarf', 200, 'Expense', 'Not Important'), (None, '2022-06-01 11:56:06.000000', 'food', 'Dinner', 179, 'Expense', 'Not Important'), (None, '2022-06-02 10:33:23.000000', 'food', 'Milk with bharath', 65, 'Expense', 'Not Important'), (None, '2022-06-02 21:37:52.000000', 'food', 'Lunch with company', 160, 'Expense', 'Not Important'), (None, '2022-06-05 19:39:27.000000', 'household', 'laundry', 350, 'Expense', 'Not Important'), (None, '2022-06-07 18:48:04.000000', 'others', 'novel', 350, 'Expense', 'Not Important'), (None, '2022-06-10 11:12:47.000000', 'food', 'Lemon tea with company', 15, 'Expense', 'Not Important'), (None, '2022-06-13 13:17:14.000000', 'education', 'Arrear and reval fee', 1400, 'Expense', 'Not Important'), (None, '2022-06-21 06:47:45.000000', 'health', 'doctor', 1000, 'Expense', 'Not Important'), (None, '2022-06-24 04:13:59.000000', 'gift', 'gift', 280, 'Expense', 'Not Important'), (None, '2022-06-27 17:06:50.000000', 'food', 'Lunch', 200, 'Expense', 'Not Important'), (None, '2022-06-29 17:55:54.000000', 'others', 'Tablet to gowdham', 8, 'Expense', 'Not Important'), (None, '2022-06-30 10:20:06.000000', 'shopping', 'shopping', 250, 'Expense', 'Important'), (None, '2022-07-02 05:42:08.000000', 'food', 'Snacks', 40, 'Expense', 'Not Important'), (None, '2022-07-02 14:02:30.000000', 'transportation', 'To chennai', 1000, 'Expense', 'Not Important'), (None, '2022-07-03 11:10:00.000000', 'food', 'lunch', 300, 'Expense', 'Not Important'), (None, '2022-07-05 06:52:53.000000', 'others', 'umbrella', 300, 'Expense', 'Not Important'), (None, '2022-07-07 13:44:08.000000', 'food', 'Ketch up', 20, 'Expense', 'Not Important'), (None, '2022-07-07 17:56:07.000000', 'shopping', 't-shirt', 300, 'Expense', 'Not Important'), (None, '2022-07-09 07:36:31.000000', 'entertainment', 'phone accessories', 300, 'Expense', 'Important'), (None, '2022-07-10 00:05:36.000000', 'transportation', 'fare', 100, 'Expense', 'Not Important'), (None, '2022-07-10 06:01:08.000000', 'food', 'Ice cream', 504, 'Expense', 'Not Important'), (None, '2022-07-21 03:34:35.000000', 'gift', 'gift', 120, 'Expense', 'Not Important'), (None, '2022-07-22 19:33:15.000000', 'food', 'Breakfast', 200, 'Expense', 'Not Important'), (None, '2022-07-29 20:59:51.000000', 'transportation', 'Rapido to pg', 43, 'Expense', 'Not Important'), (None, '2022-07-30 14:56:36.000000', 'food', 'Milk with bharath', 25, 'Expense', 'Not Important'), (None, '2022-08-02 13:24:40.000000', 'food', 'Panipoori', 40, 'Expense', 'Not Important'), (None, '2022-08-03 23:57:53.000000', 'transportation', 'Rapido to pg', 42, 'Expense', 'Not Important'), (None, '2022-08-05 21:28:51.000000', 'education', 'book', 25, 'Expense', 'Not Important'), (None, '2022-08-06 08:41:55.000000', 'transportation', 'Pg to office', 43, 'Expense', 'Not Important'), (None, '2022-08-12 02:52:44.000000', 'social life', 'Spiderman ', 363.72, 'Expense', 'Not Important'), (None, '2022-08-12 18:26:46.000000', 'others', 'hotel room', 2500, 'Expense', 'Not Important'), (None, '2022-08-13 17:24:46.000000', 'others', 'newspaper', 90, 'Expense', 'Not Important'), (None, '2022-08-23 19:37:28.000000', 'food', 'apples', 150, 'Expense', 'Not Important'), (None, '2022-08-27 00:50:32.000000', 'others', 'From Deepak', 250, 'Income', 'Not Important'), (None, '2022-08-27 00:52:01.000000', 'social life', 'movie snacks', 120, 'Expense', 'Not Important'), (None, '2022-08-27 09:56:29.000000', 'food', 'Lunch with company', 388, 'Expense', 'Not Important'), (None, '2022-08-28 12:26:55.000000', 'health', 'health', 260, 'Expense', 'Not Important'), (None, '2022-09-01 05:56:13.000000', 'social life', 'movie snacks', 100, 'Expense', 'Not Important'), (None, '2022-09-01 17:50:34.000000', 'food', 'Jan 2nd with shakur and barath', 354, 'Expense', 'Not Important'), (None, '2022-09-02 13:48:48.000000', 'shopping', 'shopping', 120, 'Expense', 'Important'), (None, '2022-09-04 12:11:41.000000', 'food', 'Pepsi', 40, 'Expense', 'Not Important'), (None, '2022-09-06 03:03:59.000000', 'food', 'Puffs', 25, 'Expense', 'Not Important'), (None, '2022-09-08 15:54:34.000000', 'others', 'Lended money returned to vishnu', 40, 'Expense', 'Not Important'), (None, '2022-09-09 18:37:52.000000', 'others', 'photo frame', 300, 'Expense', 'Not Important'), (None, '2022-09-11 23:51:10.000000', 'food', 'Lunch', 80, 'Expense', 'Not Important'), (None, '2022-09-12 08:01:53.000000', 'others', 'From abi', 20, 'Income', 'Not Important'), (None, '2022-09-13 02:08:36.000000', 'entertainment', 'phone recharge', 100, 'Expense', 'Important'), (None, '2022-09-14 05:28:53.000000', 'gift', 'souvenir', 200, 'Expense', 'Not Important'), (None, '2022-09-15 08:04:06.000000', 'education', 'books', 450, 'Expense', 'Not Important'), (None, '2022-09-18 05:19:45.000000', 'others', 'city tour', 500, 'Expense', 'Not Important'), (None, '2022-09-19 16:22:03.000000', 'transportation', 'fare', 200, 'Expense', 'Not Important'), (None, '2022-09-19 18:00:51.000000', 'others', 'pens notebook', 50, 'Expense', 'Not Important'), (None, '2022-09-25 09:46:40.000000', 'food', 'Lunch with company', 106, 'Expense', 'Not Important'), (None, '2022-10-01 04:47:04.000000', 'others', 'To vicky', 300, 'Expense', 'Not Important'), (None, '2022-10-02 01:27:59.000000', 'others', 'others', 290, 'Expense', 'Not Important'), (None, '2022-10-04 02:20:15.000000', 'others', 'To abijith and to vicky lend money returned', 500, 'Expense', 'Not Important'), (None, '2022-10-04 19:49:31.000000', 'transportation', 'Rapido', 130, 'Expense', 'Not Important'), (None, '2022-10-05 10:50:00.000000', 'transportation', \"Auto to Gobi's place\", 214, 'Expense', 'Not Important'), (None, '2022-10-08 06:19:34.000000', 'entertainment', 'parking fees', 75, 'Expense', 'Not Important'), (None, '2022-10-09 04:22:05.000000', 'food', 'Dinner', 155, 'Expense', 'Not Important'), (None, '2022-10-11 12:59:35.000000', 'food', 'Eve snack', 100, 'Expense', 'Not Important'), (None, '2022-10-13 09:20:32.000000', 'shopping', 'backpack', 500, 'Expense', 'Not Important'), (None, '2022-10-14 10:00:23.000000', 'education', 'Books', 400, 'Expense', 'Not Important'), (None, '2022-10-15 05:54:48.000000', 'food', 'juice', 150, 'Expense', 'Not Important'), (None, '2022-10-19 10:24:59.000000', 'others', 'bottle water', 60, 'Expense', 'Important'), (None, '2022-10-24 16:02:08.000000', 'food', 'Corn', 30, 'Expense', 'Not Important'), (None, '2022-10-25 13:14:42.000000', 'food', 'drink', 100, 'Expense', 'Not Important'), (None, '2022-10-25 15:59:14.000000', 'entertainment', 'ticket', 300, 'Expense', 'Not Important'), (None, '2022-10-26 09:51:03.000000', 'food', 'Milk with bharath', 40, 'Expense', 'Not Important'), (None, '2022-10-26 12:34:37.000000', 'others', 'From kumara', 200, 'Income', 'Not Important'), (None, '2022-10-27 20:11:01.000000', 'food', 'candies', 50, 'Expense', 'Not Important'), (None, '2022-10-28 13:13:43.000000', 'food', 'Puffs and coffee', 32, 'Expense', 'Not Important'), (None, '2022-10-28 14:15:58.000000', 'food', 'Parotta', 120, 'Expense', 'Not Important'), (None, '2022-11-06 13:34:01.000000', 'others', 'For company', 30, 'Expense', 'Not Important'), (None, '2022-11-07 01:55:59.000000', 'others', 'wallet', 250, 'Expense', 'Not Important'), (None, '2022-11-10 18:17:56.000000', 'social life', 'concert ticket', 1200, 'Expense', 'Not Important'), (None, '2022-11-13 18:16:23.000000', 'others', 'From dad', 1500, 'Income', 'Not Important'), (None, '2022-11-13 21:01:00.000000', 'others', 'Dinesh and maddy + 100 cash', 240, 'Income', 'Not Important'), (None, '2022-11-14 19:51:44.000000', 'food', 'Lunch with company', 138, 'Expense', 'Not Important'), (None, '2022-11-17 04:41:57.000000', 'others', 'items', 300, 'Expense', 'Not Important'), (None, '2022-11-20 15:00:03.000000', 'transportation', 'Train to vnr', 325, 'Expense', 'Not Important'), (None, '2022-11-21 12:09:24.000000', 'food', 'oranges', 30, 'Expense', 'Not Important'), (None, '2022-11-24 15:49:15.000000', 'others', 'bananas', 35, 'Expense', 'Not Important'), (None, '2022-11-28 23:41:38.000000', 'others', 'Recharge by gowdham', 479, 'Expense', 'Not Important'), (None, '2022-12-01 14:20:41.000000', 'transportation', 'Rapido', 35, 'Expense', 'Not Important'), (None, '2022-12-02 14:00:01.000000', 'food', 'Lunch + chocolate for preethi', 171, 'Expense', 'Not Important'), (None, '2022-12-03 14:28:43.000000', 'others', 'novel', 250, 'Expense', 'Not Important'), (None, '2022-12-03 23:09:10.000000', 'food', 'cafe', 75, 'Expense', 'Not Important'), (None, '2022-12-05 02:53:27.000000', 'food', 'Lunch with not preethi', 135.5, 'Expense', 'Not Important'), (None, '2022-12-07 07:35:41.000000', 'food', 'Dinner', 78, 'Expense', 'Not Important'), (None, '2022-12-07 19:12:56.000000', 'food', 'cooking course', 600, 'Expense', 'Not Important'), (None, '2022-12-08 07:52:18.000000', 'shopping', 'cosmetics', 300, 'Expense', 'Not Important'), (None, '2022-12-10 06:28:54.000000', 'others', 'To auto anna', 50, 'Expense', 'Not Important'), (None, '2022-12-10 12:47:19.000000', 'gift', 'souvenir', 100, 'Expense', 'Not Important'), (None, '2022-12-11 04:39:53.000000', 'food', 'Dinner', 70, 'Expense', 'Not Important'), (None, '2022-12-21 13:18:28.000000', 'food', 'Lemon tea', 18, 'Expense', 'Not Important'), (None, '2022-12-26 01:50:07.000000', 'others', 'keychain', 50, 'Expense', 'Not Important'), (None, '2023-01-01 07:08:15.000000', 'social life', 'pair sunglasses', 300, 'Expense', 'Not Important'), (None, '2023-01-02 16:16:17.000000', 'shopping', 'shirt', 400, 'Expense', 'Not Important'), (None, '2023-01-06 04:11:22.000000', 'food', 'Lunch with company', 188, 'Expense', 'Not Important'), (None, '2023-01-06 11:11:09.000000', 'shopping', 'bag', 700, 'Expense', 'Not Important'), (None, '2023-01-11 16:23:33.000000', 'shopping', 'Belt', 130, 'Expense', 'Not Important'), (None, '2023-01-14 12:40:15.000000', 'food', 'fruit basket', 150, 'Expense', 'Not Important'), (None, '2023-01-14 23:15:59.000000', 'others', 'school supplies', 350, 'Expense', 'Not Important'), (None, '2023-01-15 03:46:37.000000', 'food', 'Breakfast', 40, 'Expense', 'Not Important'), (None, '2023-01-16 19:25:07.000000', 'transportation', 'street food', 75, 'Expense', 'Important'), (None, '2023-01-16 23:28:05.000000', 'food', 'Dinner', 90, 'Expense', 'Not Important'), (None, '2023-01-20 03:16:05.000000', 'social life', 'movie ticket', 250, 'Expense', 'Not Important'), (None, '2023-01-20 16:11:19.000000', 'food', 'Water', 30, 'Expense', 'Important'), (None, '2023-01-24 15:37:39.000000', 'food', 'groceries', 600, 'Expense', 'Not Important'), (None, '2023-01-24 16:14:19.000000', 'transportation', 'Train cbe to chn', 201.8, 'Expense', 'Not Important'), (None, '2023-01-25 13:02:22.000000', 'others', 'From Deepak', 250, 'Income', 'Not Important'), (None, '2023-02-04 05:23:52.000000', 'food', 'Milk with bharath', 25, 'Expense', 'Not Important'), (None, '2023-02-05 03:21:38.000000', 'others', 'bottles water', 25, 'Expense', 'Important'), (None, '2023-02-07 14:00:49.000000', 'education', 'stationery', 180, 'Expense', 'Not Important'), (None, '2023-02-07 19:15:14.000000', 'food', 'Dinner with barath', 504, 'Expense', 'Not Important'), (None, '2023-02-08 00:29:41.000000', 'food', 'groceries', 250, 'Expense', 'Not Important'), (None, '2023-02-09 22:25:41.000000', 'social life', 'Badminton', 200, 'Expense', 'Not Important'), (None, '2023-02-10 01:34:00.000000', 'social life', 'hours project', 400, 'Expense', 'Not Important'), (None, '2023-02-11 19:56:14.000000', 'others', 'umbrella', 150, 'Expense', 'Not Important'), (None, '2023-02-15 09:15:22.000000', 'social life', None, 1700, 'Expense', 'Not Important'), (None, '2023-02-17 15:04:00.000000', 'others', 'bakery', 150, 'Expense', 'Not Important'), (None, '2023-02-19 08:55:56.000000', 'food', 'drink', 100, 'Expense', 'Not Important'), (None, '2023-02-20 12:08:40.000000', 'food', 'juice', 120, 'Expense', 'Not Important'), (None, '2023-02-21 10:28:47.000000', 'transportation', 'bus pass', 100, 'Expense', 'Not Important'), (None, '2023-02-22 05:48:38.000000', 'social life', 'hours appointment doctor', 300, 'Expense', 'Not Important'), (None, '2023-02-23 07:48:28.000000', 'household', 'Mirror', 70, 'Expense', 'Not Important'), (None, '2023-02-25 03:29:45.000000', 'food', 'Milk with bharath', 70, 'Expense', 'Not Important'), (None, '2023-02-25 23:57:30.000000', 'food', 'Snack with bharath', 40, 'Expense', 'Not Important'), (None, '2023-02-26 15:39:33.000000', 'food', \"McDonald's with company\", 211, 'Expense', 'Not Important'), (None, '2023-03-01 01:48:08.000000', 'others', 'popcorn', 60, 'Expense', 'Not Important'), (None, '2023-03-03 05:08:16.000000', 'entertainment', 'education', 3470, 'Expense', 'Important'), (None, '2023-03-08 22:04:08.000000', 'shopping', 'Cap', 140, 'Expense', 'Not Important'), (None, '2023-03-10 01:24:11.000000', 'transportation', 'Bus ticket', 1575, 'Expense', 'Not Important'), (None, '2023-03-14 15:27:42.000000', 'food', 'Pizza', 339.15, 'Expense', 'Not Important'), (None, '2023-03-16 07:53:28.000000', 'transportation', 'Travel to koyambedu', 138, 'Expense', 'Not Important'), (None, '2023-03-17 17:47:45.000000', 'others', 'pen', 50, 'Expense', 'Not Important'), (None, '2023-03-18 06:50:46.000000', 'food', None, 33, 'Expense', 'Not Important'), (None, '2023-03-18 16:22:24.000000', 'transportation', 'Rapido', 50, 'Expense', 'Not Important'), (None, '2023-03-19 11:55:17.000000', 'social life', 'movie ticket', 500, 'Expense', 'Not Important'), (None, '2023-03-21 15:38:02.000000', 'others', 'Sent to barath', 100, 'Expense', 'Not Important'), (None, '2023-03-23 22:26:50.000000', 'food', 'Milk with bharath', 25, 'Expense', 'Not Important'), (None, '2023-03-25 23:46:17.000000', 'others', 'To vicky', 200, 'Expense', 'Not Important'), (None, '2023-03-28 01:03:20.000000', 'food', 'coffee', 120, 'Expense', 'Not Important'), (None, '2023-03-30 14:34:32.000000', 'others', 'days hotel', 2000, 'Expense', 'Not Important'), (None, '2023-04-05 10:57:16.000000', 'others', 'Kumara', 170, 'Income', 'Not Important'), (None, '2023-04-09 02:44:12.000000', 'food', 'Dinner', 66, 'Expense', 'Not Important'), (None, '2023-04-11 06:36:23.000000', 'food', 'cooking class', 600, 'Expense', 'Not Important'), (None, '2023-04-11 15:02:05.000000', 'others', 'From stu', 240, 'Income', 'Not Important'), (None, '2023-04-13 02:40:17.000000', 'food', 'Snacks', 85, 'Expense', 'Not Important'), (None, '2023-04-14 00:31:08.000000', 'others', 'flowers', 400, 'Expense', 'Not Important'), (None, '2023-04-15 02:43:20.000000', 'others', 'From gowdham', 340, 'Income', 'Not Important'), (None, '2023-04-17 13:51:35.000000', 'food', 'Breakfast', 70, 'Expense', 'Not Important'), (None, '2023-04-19 01:52:40.000000', 'others', 'To kumara', 200, 'Expense', 'Not Important'), (None, '2023-04-19 03:18:22.000000', 'social life', 'entertainment', 230, 'Expense', 'Not Important'), (None, '2023-04-19 22:05:36.000000', 'transportation', 'Train to vnr', 725, 'Expense', 'Not Important'), (None, '2023-04-24 15:40:38.000000', 'shopping', 'Mask', 20, 'Expense', 'Not Important'), (None, '2023-04-25 22:21:02.000000', 'food', 'Lunch with company', 145, 'Expense', 'Not Important'), (None, '2023-04-27 12:43:05.000000', 'social life', 'weekend stay', 2000, 'Expense', 'Not Important'), (None, '2023-04-27 21:41:52.000000', 'food', 'Snack', 40, 'Expense', 'Not Important'), (None, '2023-04-28 05:56:01.000000', 'food', 'Lunch', 302, 'Expense', 'Not Important'), (None, '2023-04-29 03:05:12.000000', 'transportation', 'Rapido', 58, 'Expense', 'Not Important'), (None, '2023-05-02 10:02:26.000000', 'food', 'Water', 20, 'Expense', 'Important'), (None, '2023-05-05 14:17:37.000000', 'food', 'Kfc dinner', 641, 'Expense', 'Not Important'), (None, '2023-05-05 19:58:00.000000', 'food', 'Snack', 40, 'Expense', 'Not Important'), (None, '2023-05-13 11:43:43.000000', 'education', 'class', 500, 'Expense', 'Not Important'), (None, '2023-05-16 03:04:56.000000', 'food', 'Panipoori', 40, 'Expense', 'Not Important'), (None, '2023-05-16 22:26:37.000000', 'transportation', 'fare', 120, 'Expense', 'Not Important'), (None, '2023-05-17 00:16:37.000000', 'others', 'From dad', 1500, 'Income', 'Not Important'), (None, '2023-05-17 04:59:12.000000', 'food', 'Milk with bharath', 25, 'Expense', 'Not Important'), (None, '2023-05-17 09:30:22.000000', 'food', 'Snack', 94, 'Expense', 'Not Important'), (None, '2023-05-21 13:36:32.000000', 'social life', 'Games ', 100, 'Expense', 'Not Important'), (None, '2023-05-23 19:45:21.000000', 'health', 'dentist', 450, 'Expense', 'Not Important'), (None, '2023-05-24 00:07:38.000000', 'food', 'sandwich', 50, 'Expense', 'Not Important'), (None, '2023-05-26 06:53:45.000000', 'others', 'soda', 45, 'Expense', 'Not Important'), (None, '2023-05-30 07:59:48.000000', 'others', 'Siva + 100 cash', 70, 'Income', 'Not Important'), (None, '2023-05-31 07:32:48.000000', 'others', 'popcorn', 60, 'Expense', 'Not Important'), (None, '2023-06-01 16:25:42.000000', 'allowance', 'From dad', 2000, 'Income', 'Not Important'), (None, '2023-06-04 19:57:40.000000', 'food', 'To barath', 20, 'Expense', 'Not Important'), (None, '2023-06-05 18:14:36.000000', 'food', 'Dinner', 324, 'Expense', 'Not Important'), (None, '2023-06-10 18:33:58.000000', 'food', 'Water', 20, 'Expense', 'Important'), (None, '2023-06-12 06:25:21.000000', 'food', 'Snacks with preethi and azar', 176, 'Expense', 'Not Important'), (None, '2023-06-13 02:14:23.000000', 'food', 'snacks', 100, 'Expense', 'Not Important'), (None, '2023-06-14 18:14:30.000000', 'food', 'Lunch with company', 280, 'Expense', 'Not Important'), (None, '2023-06-15 01:49:15.000000', 'food', 'Snack', 15, 'Expense', 'Not Important'), (None, '2023-06-17 16:06:18.000000', 'food', 'Lunch', 160, 'Expense', 'Not Important'), (None, '2023-06-20 02:35:49.000000', 'shopping', 'scarf', 200, 'Expense', 'Not Important'), (None, '2023-06-20 16:26:45.000000', 'social life', 'concert', 1200, 'Expense', 'Not Important'), (None, '2023-06-22 04:01:01.000000', 'transportation', 'To ksr station', 153, 'Expense', 'Not Important'), (None, '2023-06-24 15:54:43.000000', 'food', 'groceries', 750, 'Expense', 'Not Important'), (None, '2023-06-24 17:03:44.000000', 'food', 'groceries', 600, 'Expense', 'Not Important'), (None, '2023-06-26 03:59:54.000000', 'entertainment', 'tickets', 800, 'Expense', 'Not Important'), (None, '2023-06-30 00:34:05.000000', 'food', 'Dinner with gowdham', 130, 'Expense', 'Not Important'), (None, '2023-06-30 02:23:24.000000', 'shopping', 'accessories', 400, 'Expense', 'Not Important'), (None, '2023-06-30 11:55:25.000000', 'entertainment', 'entry fees', 75, 'Expense', 'Not Important'), (None, '2023-07-01 20:20:12.000000', 'food', 'fruits', 50.5, 'Expense', 'Not Important'), (None, '2023-07-03 13:31:15.000000', 'others', 'packets chips', 20, 'Expense', 'Not Important'), (None, '2023-07-05 12:11:09.000000', 'others', 'To lended people', 300, 'Expense', 'Not Important'), (None, '2023-07-05 14:45:06.000000', 'food', 'Banana', 10, 'Expense', 'Not Important'), (None, '2023-07-06 07:02:17.000000', 'others', 'To siva', 100, 'Expense', 'Not Important'), (None, '2023-07-07 00:09:34.000000', 'food', 'Random stuff for drinks', 111, 'Expense', 'Not Important'), (None, '2023-07-09 05:16:05.000000', 'food', 'Snack', 102, 'Expense', 'Not Important'), (None, '2023-07-09 19:33:40.000000', 'food', 'fruit juice', 90, 'Expense', 'Not Important'), (None, '2023-07-10 11:50:55.000000', 'transportation', 'Bommasandra to pg', 199, 'Expense', 'Not Important'), (None, '2023-07-12 12:12:42.000000', 'food', 'Snack', 65, 'Expense', 'Not Important'), (None, '2023-07-13 15:06:59.000000', 'entertainment', 'tickets', 800, 'Expense', 'Not Important'), (None, '2023-07-13 22:09:08.000000', 'food', 'Snacks', 75, 'Expense', 'Not Important'), (None, '2023-07-15 19:30:13.000000', 'others', 'bottle water', 20, 'Expense', 'Important'), (None, '2023-07-17 14:02:29.000000', 'others', 'gym subscription', 1000, 'Expense', 'Important'), (None, '2023-07-18 11:07:19.000000', 'entertainment', 'phone case', 500, 'Expense', 'Important'), (None, '2023-07-20 08:18:45.000000', 'education', 'books', 350, 'Expense', 'Not Important'), (None, '2023-07-24 00:00:57.000000', 'others', 'To vicky', 80, 'Expense', 'Not Important'), (None, '2023-07-24 18:37:35.000000', 'transportation', 'Refund for bus ticket', 60, 'Expense', 'Not Important'), (None, '2023-07-26 03:44:55.000000', 'others', 'From dad', 1000, 'Income', 'Not Important'), (None, '2023-07-26 16:29:23.000000', 'transportation', 'taxi ride', 300, 'Expense', 'Not Important'), (None, '2023-07-30 22:42:23.000000', 'transportation', 'Bus to Bangalore', 1365, 'Expense', 'Not Important'), (None, '2023-08-02 09:21:43.000000', 'education', 'stationery', 50, 'Expense', 'Not Important'), (None, '2023-08-06 02:20:30.000000', 'transportation', 'Rapido to pg', 43, 'Expense', 'Not Important'), (None, '2023-08-11 02:17:14.000000', 'food', 'Lunch with company', 133, 'Expense', 'Not Important'), (None, '2023-08-12 12:30:06.000000', 'transportation', 'Took from sbi', 200, 'Expense', 'Not Important'), (None, '2023-08-13 12:04:28.000000', 'food', 'Momos', 195, 'Expense', 'Not Important'), (None, '2023-08-15 07:26:23.000000', 'others', 'To kumara', 100, 'Expense', 'Not Important'), (None, '2023-08-15 17:41:52.000000', 'others', 'card', 20, 'Expense', 'Not Important'), (None, '2023-08-18 08:58:02.000000', 'others', 'pack biscuits', 50, 'Expense', 'Not Important'), (None, '2023-08-19 14:18:15.000000', 'others', 'notebook', 80, 'Expense', 'Not Important'), (None, '2023-08-21 13:24:37.000000', 'food', 'food', 300, 'Expense', 'Important'), (None, '2023-08-24 06:31:53.000000', 'shopping', 'bag', 900, 'Expense', 'Not Important'), (None, '2023-08-28 06:50:51.000000', 'others', 'From shakur', 140, 'Income', 'Not Important'), (None, '2023-08-30 22:26:20.000000', 'others', 'From vicky', 80, 'Income', 'Not Important'), (None, '2023-08-31 05:18:12.000000', 'household', 'household', 240, 'Expense', 'Not Important'), (None, '2023-09-01 19:30:26.000000', 'food', 'dinner friends', 200, 'Expense', 'Not Important'), (None, '2023-09-02 14:26:11.000000', 'food', 'Lunch', 243, 'Expense', 'Not Important'), (None, '2023-09-02 15:54:05.000000', 'food', 'Tea lights', 84, 'Expense', 'Not Important'), (None, '2023-09-04 22:22:52.000000', 'food', 'Dinner with barath', 239, 'Expense', 'Not Important'), (None, '2023-09-07 19:27:05.000000', 'health', 'fitness tracker', 1200, 'Expense', 'Not Important'), (None, '2023-09-10 02:13:18.000000', 'food', 'Shawarma', 80, 'Expense', 'Not Important'), (None, '2023-09-14 01:38:44.000000', 'others', 'gym membership', 1500, 'Expense', 'Important'), (None, '2023-09-14 14:54:03.000000', 'social life', 'birthday gift', 400, 'Expense', 'Not Important'), (None, '2023-09-14 15:50:00.000000', 'social life', 'movie ticket', 400, 'Expense', 'Not Important'), (None, '2023-09-15 09:27:49.000000', 'others', 'From gpay', 5, 'Income', 'Not Important'), (None, '2023-09-16 06:37:21.000000', 'food', 'coffee shop', 120, 'Expense', 'Not Important'), (None, '2023-09-17 17:32:23.000000', 'shopping', 'Full hand and a hoodie', 1800, 'Expense', 'Not Important'), (None, '2023-09-17 19:36:44.000000', 'food', 'Dinner with aravind', 373, 'Expense', 'Not Important'), (None, '2023-09-19 09:59:19.000000', 'others', 'magazine', 60, 'Expense', 'Not Important'), (None, '2023-09-20 02:12:47.000000', 'food', 'meal', 150, 'Expense', 'Not Important'), (None, '2023-09-23 13:07:09.000000', 'health', 'doctor s appointment', 700, 'Expense', 'Not Important'), (None, '2023-09-23 16:17:29.000000', 'food', 'Snack with preethi', 59, 'Expense', 'Not Important'), (None, '2023-09-25 23:59:29.000000', 'social life', 'movie', 300, 'Expense', 'Not Important'), (None, '2023-09-26 01:59:37.000000', 'transportation', 'fare', 150, 'Expense', 'Not Important'), (None, '2023-09-29 10:09:12.000000', 'household', 'Stuffs', 336, 'Expense', 'Not Important'), (None, '2023-09-30 03:59:10.000000', 'food', 'Lunch with barath', 85, 'Expense', 'Not Important'), (None, '2023-09-30 04:07:30.000000', 'food', 'Dinner with gowdham', 120, 'Expense', 'Not Important'), (None, '2023-09-30 22:20:15.000000', 'entertainment', 'postcard', 75, 'Expense', 'Not Important'), (None, '2023-10-01 09:13:08.000000', 'entertainment', 'education', 270, 'Expense', 'Important'), (None, '2023-10-03 20:17:59.000000', 'food', 'veggies', 200, 'Expense', 'Not Important'), (None, '2023-10-04 16:17:21.000000', 'food', 'Brownie', 50, 'Expense', 'Not Important'), (None, '2023-10-05 23:12:35.000000', 'allowance', 'From dad', 8000, 'Income', 'Not Important'), (None, '2023-10-08 15:46:57.000000', 'others', 'flowers', 300, 'Expense', 'Not Important'), (None, '2023-10-10 17:59:13.000000', 'food', 'Lunch with barath', 115, 'Expense', 'Not Important'), (None, '2023-10-11 22:57:23.000000', 'others', 'From dad', 10000, 'Income', 'Not Important'), (None, '2023-10-12 02:58:38.000000', 'transportation', 'bus ticket', 200, 'Expense', 'Not Important'), (None, '2023-10-12 18:37:12.000000', 'food', 'drink', 50, 'Expense', 'Not Important'), (None, '2023-10-14 14:22:13.000000', 'others', 'From dad', 1500, 'Income', 'Not Important'), (None, '2023-10-17 08:48:45.000000', 'food', 'groceries', 200, 'Expense', 'Not Important'), (None, '2023-10-20 05:48:42.000000', 'food', 'Dinner with aravind and buddies', 491, 'Expense', 'Not Important'), (None, '2023-10-20 08:50:34.000000', 'household', None, 303, 'Expense', 'Not Important'), (None, '2023-10-20 11:06:06.000000', 'food', 'Lunch with company', 150, 'Expense', 'Not Important'), (None, '2023-10-20 12:52:39.000000', 'others', 'From kumara', 30, 'Income', 'Not Important'), (None, '2023-10-22 13:24:51.000000', 'food', 'Creamstone', 289, 'Expense', 'Not Important'), (None, '2023-10-23 07:55:07.000000', 'food', 'Tamen', 324.7, 'Expense', 'Not Important'), (None, '2023-10-25 01:59:12.000000', 'shopping', 'jacket worth', 800, 'Expense', 'Not Important'), (None, '2023-10-29 00:07:08.000000', 'transportation', 'taxi ride', 400, 'Expense', 'Not Important'), (None, '2023-10-31 13:24:34.000000', 'shopping', 'bag', 1000, 'Expense', 'Not Important'), (None, '2023-10-31 19:52:54.000000', 'others', 'gym fees', 200, 'Expense', 'Important'), (None, '2023-11-01 21:35:58.000000', 'others', 'magazine', 150, 'Expense', 'Not Important'), (None, '2023-11-03 09:17:24.000000', 'food', 'Milk with bharath', 40, 'Expense', 'Not Important'), (None, '2023-11-07 09:52:57.000000', 'food', 'Vadapaav', 75, 'Expense', 'Not Important'), (None, '2023-11-08 20:26:10.000000', 'social life', 'pair shoes', 2000, 'Expense', 'Not Important'), (None, '2023-11-09 10:12:58.000000', 'salary', 'Salary', 8000, 'Income', 'Not Important'), (None, '2023-11-10 23:16:38.000000', 'food', 'Snacks', 67, 'Expense', 'Not Important'), (None, '2023-11-10 23:21:07.000000', 'others', 'From vicky', 100, 'Income', 'Not Important'), (None, '2023-11-11 15:45:57.000000', 'entertainment', 'phone', 500, 'Expense', 'Important'), (None, '2023-11-15 12:36:37.000000', 'food', 'snack', 60, 'Expense', 'Not Important'), (None, '2023-11-16 19:16:32.000000', 'social life', 'sports equipment', 1000, 'Expense', 'Not Important'), (None, '2023-11-17 22:38:17.000000', 'transportation', 'bus fare', 200, 'Expense', 'Not Important'), (None, '2023-11-19 21:24:09.000000', 'others', 'flowers', 100, 'Expense', 'Not Important'), (None, '2023-11-21 06:06:23.000000', 'entertainment', 'parking fees', 200, 'Expense', 'Not Important'), (None, '2023-11-22 08:51:09.000000', 'education', 'book', 300, 'Expense', 'Not Important'), (None, '2023-11-30 04:59:00.000000', 'food', 'Eggs', 83, 'Expense', 'Not Important'), (None, '2023-12-02 12:52:30.000000', 'entertainment', 'game', 350, 'Expense', 'Not Important'), (None, '2023-12-03 01:55:46.000000', 'food', 'Lunch with company', 97, 'Expense', 'Not Important'), (None, '2023-12-06 20:22:26.000000', 'transportation', 'taxi ride', 220, 'Expense', 'Not Important'), (None, '2023-12-07 22:15:14.000000', 'food', 'snack', 50, 'Expense', 'Not Important'), (None, '2023-12-08 21:51:09.000000', 'food', 'Milk with bharath', 110, 'Expense', 'Not Important'), (None, '2023-12-11 22:20:42.000000', 'food', 'Snacks', 70, 'Expense', 'Not Important'), (None, '2023-12-12 10:49:02.000000', 'food', 'Brunch', 105, 'Expense', 'Not Important'), (None, '2023-12-13 16:50:22.000000', 'food', 'Egg', 30, 'Expense', 'Not Important'), (None, '2023-12-13 17:19:34.000000', 'food', 'Coffee and thattai', 14, 'Expense', 'Not Important'), (None, '2023-12-24 08:31:13.000000', 'others', 'Lended money returned to kumara', 30, 'Expense', 'Not Important'), (None, '2023-12-25 17:08:03.000000', 'food', 'Paani poori', 25, 'Expense', 'Not Important'), (None, '2023-12-27 15:25:37.000000', 'food', 'Dinner', 301.15, 'Expense', 'Not Important'), (None, '2023-12-28 12:08:56.000000', 'others', 'lunchbox', 200, 'Expense', 'Not Important'), (None, '2023-12-28 18:52:19.000000', 'others', 'packs pasta', 90, 'Expense', 'Not Important'), (None, '2023-12-29 18:53:53.000000', 'others', 'Got from gobi', 2000, 'Income', 'Not Important'), (None, '2024-01-04 02:39:17.000000', 'others', 'magazine', 75, 'Expense', 'Not Important'), (None, '2024-01-05 16:11:07.000000', 'transportation', 'To egmore', 270, 'Expense', 'Not Important'), (None, '2024-01-06 03:10:08.000000', 'food', 'groceries', 500, 'Expense', 'Not Important'), (None, '2024-01-07 16:05:30.000000', 'social life', 'pairs socks', 120, 'Expense', 'Not Important'), (None, '2024-01-07 22:36:56.000000', 'health', 'doctor appointment', 350, 'Expense', 'Not Important'), (None, '2024-01-08 08:41:41.000000', 'shopping', 'Showergel', 196, 'Expense', 'Not Important'), (None, '2024-01-09 23:09:42.000000', 'gift', 'gift', 3480, 'Expense', 'Not Important'), (None, '2024-01-11 23:18:32.000000', 'food', 'Lunch with stu', 100, 'Expense', 'Not Important'), (None, '2024-01-13 07:05:13.000000', 'food', 'Lunch', 30, 'Expense', 'Not Important'), (None, '2024-01-13 13:43:29.000000', 'household', 'Bean bag', 2099, 'Expense', 'Not Important'), (None, '2024-01-18 06:36:19.000000', 'transportation', 'transportation', 220, 'Expense', 'Important'), (None, '2024-01-19 10:45:42.000000', 'transportation', 'car wash', 300, 'Expense', 'Not Important'), (None, '2024-01-20 15:22:12.000000', 'shopping', 'cosmetics', 200, 'Expense', 'Not Important'), (None, '2024-01-25 09:49:52.000000', 'others', 'eggs', 60, 'Expense', 'Not Important'), (None, '2024-01-26 19:36:24.000000', 'food', 'candy bar', 45, 'Expense', 'Not Important'), (None, '2024-01-30 16:16:06.000000', 'transportation', 'Auto to laxmi mills', 120, 'Expense', 'Not Important'), (None, '2024-01-31 01:38:22.000000', 'education', 'fee', 75, 'Expense', 'Important'), (None, '2024-01-31 22:53:44.000000', 'food', 'coffee', 75, 'Expense', 'Not Important'), (None, '2024-02-01 21:10:57.000000', 'allowance', 'From dad', 1000, 'Income', 'Not Important'), (None, '2024-02-05 20:09:24.000000', 'food', 'gum', 40, 'Expense', 'Not Important'), (None, '2024-02-08 00:14:56.000000', 'social life', 'concert ticket', 900, 'Expense', 'Not Important'), (None, '2024-02-08 23:53:40.000000', 'food', 'Lunch with company', 40, 'Expense', 'Not Important'), (None, '2024-02-09 11:35:25.000000', 'health', 'doctor visit', 1000, 'Expense', 'Not Important'), (None, '2024-02-12 00:09:16.000000', 'others', 'bookmark', 70, 'Expense', 'Not Important'), (None, '2024-02-16 01:14:25.000000', 'food', 'Snacks', 37, 'Expense', 'Not Important'), (None, '2024-02-17 04:06:11.000000', 'food', 'Panipoori', 20, 'Expense', 'Not Important'), (None, '2024-02-20 19:53:56.000000', 'food', 'Lunch', 80, 'Expense', 'Not Important'), (None, '2024-02-21 12:37:17.000000', 'others', 'optician', 900, 'Expense', 'Not Important'), (None, '2024-02-22 12:32:23.000000', 'shopping', 'Shoe', 500, 'Expense', 'Not Important'), (None, '2024-02-23 09:16:53.000000', 'transportation', 'bus fare', 300, 'Expense', 'Not Important'), (None, '2024-02-26 18:49:35.000000', 'others', 'From dad', 500, 'Income', 'Not Important'), (None, '2024-02-26 22:55:20.000000', 'food', 'Snacks', 115, 'Expense', 'Not Important'), (None, '2024-02-28 09:34:17.000000', 'transportation', 'Metro', 60, 'Expense', 'Not Important'), (None, '2024-02-28 21:19:14.000000', 'transportation', 'Taxi', 80, 'Expense', 'Not Important'), (None, '2024-03-02 08:47:01.000000', 'allowance', 'From dad', 1000, 'Income', 'Not Important'), (None, '2024-03-02 15:02:09.000000', 'food', 'tea', 70, 'Expense', 'Not Important'), (None, '2024-03-03 00:05:50.000000', 'shopping', 'hat', 250, 'Expense', 'Not Important'), (None, '2024-03-07 16:54:27.000000', 'household', 'family meal', 400, 'Expense', 'Not Important'), (None, '2024-03-09 20:12:56.000000', 'food', 'Breakfast', 60, 'Expense', 'Not Important'), (None, '2024-03-10 22:11:07.000000', 'others', 'pen', 20, 'Expense', 'Not Important'), (None, '2024-03-11 03:16:08.000000', 'transportation', 'street food', 120, 'Expense', 'Important'), (None, '2024-03-17 03:00:06.000000', 'household', 'furniture', 1500, 'Expense', 'Not Important'), (None, '2024-03-19 09:43:00.000000', 'allowance', 'From dad', 1000, 'Income', 'Not Important'), (None, '2024-03-19 14:24:19.000000', 'others', 'To gobi', 1500, 'Expense', 'Not Important'), (None, '2024-03-23 00:08:36.000000', 'social life', 'pair shoes', 1200, 'Expense', 'Not Important'), (None, '2024-03-24 20:13:28.000000', 'food', 'meal', 150, 'Expense', 'Not Important'), (None, '2024-03-25 10:42:53.000000', 'food', 'Cakepark', 125, 'Expense', 'Not Important'), (None, '2024-03-30 23:36:38.000000', 'food', 'Panipoori', 80, 'Expense', 'Not Important'), (None, '2024-04-01 08:33:46.000000', 'others', 'bookmark', 30, 'Expense', 'Not Important'), (None, '2024-04-02 09:04:44.000000', 'food', 'Lunch with company', 148, 'Expense', 'Not Important'), (None, '2024-04-08 21:48:35.000000', 'food', 'Sent to preethi', 107, 'Expense', 'Not Important'), (None, '2024-04-09 11:59:08.000000', 'food', 'Breakfast', 30, 'Expense', 'Not Important'), (None, '2024-04-10 19:27:38.000000', 'food', 'Lunch with company', 128, 'Expense', 'Not Important'), (None, '2024-04-13 00:22:38.000000', 'others', 'social life', 310, 'Expense', 'Not Important'), (None, '2024-04-13 07:52:40.000000', 'food', 'fruits', 250, 'Expense', 'Not Important'), (None, '2024-04-16 17:35:54.000000', 'others', 'To gowdham', 150, 'Expense', 'Not Important'), (None, '2024-04-18 18:27:32.000000', 'food', 'Lunch with company', 110, 'Expense', 'Not Important'), (None, '2024-04-22 20:56:00.000000', 'food', 'Panipoori', 20, 'Expense', 'Not Important'), (None, '2024-04-25 20:11:49.000000', 'transportation', 'fare', 150, 'Expense', 'Not Important'), (None, '2024-04-28 05:43:14.000000', 'transportation', 'train ticket', 200, 'Expense', 'Not Important'), (None, '2024-05-01 22:41:36.000000', 'food', 'Dinner', 465, 'Expense', 'Not Important'), (None, '2024-05-02 09:14:18.000000', 'others', 'ice cream', 75, 'Expense', 'Not Important'), (None, '2024-05-02 21:45:31.000000', 'food', 'Beer', 150, 'Expense', 'Not Important'), (None, '2024-05-03 01:06:05.000000', 'education', 'stationery', 40, 'Expense', 'Not Important'), (None, '2024-05-05 06:43:26.000000', 'food', 'Shopping', 241, 'Expense', 'Important'), (None, '2024-05-05 08:16:07.000000', 'food', 'dinner', 150, 'Expense', 'Not Important'), (None, '2024-05-05 19:42:42.000000', 'others', 'mangoes', 100, 'Expense', 'Not Important'), (None, '2024-05-09 23:50:09.000000', 'transportation', 'Cab', 306, 'Expense', 'Not Important'), (None, '2024-05-10 19:41:45.000000', 'others', 'To gobi 1st 1/4th', 500, 'Expense', 'Not Important'), (None, '2024-05-13 17:43:01.000000', 'food', 'Breakfast with stu', 110, 'Expense', 'Not Important'), (None, '2024-05-14 17:12:18.000000', 'education', 'stationery', 50, 'Expense', 'Not Important'), (None, '2024-05-15 07:58:24.000000', 'food', 'Ramen with gobi', 380, 'Expense', 'Not Important'), (None, '2024-05-18 10:51:50.000000', 'food', 'Horlicks', 15, 'Expense', 'Not Important'), (None, '2024-05-20 06:10:13.000000', 'others', 'wallet', 500, 'Expense', 'Not Important'), (None, '2024-05-21 01:47:55.000000', 'household', 'family dinner', 500, 'Expense', 'Not Important'), (None, '2024-05-25 18:39:24.000000', 'transportation', 'car service', 700, 'Expense', 'Not Important'), (None, '2024-05-26 02:24:34.000000', 'transportation', 'train ticket', 200, 'Expense', 'Not Important'), (None, '2024-05-27 08:59:35.000000', 'food', 'Milk with bharath', 25, 'Expense', 'Not Important'), (None, '2024-05-29 03:53:04.000000', 'others', 'From gowdham', 260, 'Income', 'Not Important'), (None, '2024-05-29 05:51:19.000000', 'food', 'Bun', 18, 'Expense', 'Not Important'), (None, '2024-05-29 23:15:33.000000', 'shopping', 'jacket', 700, 'Expense', 'Not Important'), (None, '2024-06-01 05:32:09.000000', 'education', 'membership', 300, 'Expense', 'Not Important'), (None, '2024-06-01 06:47:35.000000', 'entertainment', 'manicure', 200, 'Expense', 'Not Important'), (None, '2024-06-01 09:34:18.000000', 'food', 'Kfc date with myself', 259, 'Expense', 'Not Important'), (None, '2024-06-02 05:40:18.000000', 'transportation', 'fare', 90, 'Expense', 'Not Important'), (None, '2024-06-02 22:08:35.000000', 'food', 'snacks', 100, 'Expense', 'Not Important'), (None, '2024-06-03 07:47:15.000000', 'others', 'From vicky', 310, 'Income', 'Not Important'), (None, '2024-06-04 00:49:02.000000', 'health', 'dentist', 1200, 'Expense', 'Not Important'), (None, '2024-06-07 10:13:49.000000', 'food', 'groceries', 1200, 'Expense', 'Not Important'), (None, '2024-06-07 21:15:26.000000', 'food', 'Coffee + biscuit', 15, 'Expense', 'Not Important'), (None, '2024-06-10 15:33:27.000000', 'food', 'Dinner', 95, 'Expense', 'Not Important'), (None, '2024-06-11 10:04:40.000000', 'food', 'tea', 80, 'Expense', 'Not Important'), (None, '2024-06-11 11:49:58.000000', 'transportation', 'Rapido + toll', 286, 'Expense', 'Not Important'), (None, '2024-06-13 07:40:48.000000', 'transportation', 'fare', 350, 'Expense', 'Not Important'), (None, '2024-06-16 20:41:07.000000', 'social life', 'movie rental', 100, 'Expense', 'Not Important'), (None, '2024-06-17 15:37:20.000000', 'food', 'coffee', 60, 'Expense', 'Not Important'), (None, '2024-06-17 19:05:20.000000', 'food', 'Kfc dinner', 348, 'Expense', 'Not Important'), (None, '2024-06-21 11:04:03.000000', 'others', 'From dad', 2000, 'Income', 'Not Important'), (None, '2024-06-24 13:48:25.000000', 'others', 'To karthi', 100, 'Expense', 'Not Important'), (None, '2024-06-27 03:28:41.000000', 'shopping', 'Hoodie for gobi', 399, 'Expense', 'Not Important'), (None, '2024-06-27 22:40:15.000000', 'others', 'From dad', 500, 'Income', 'Not Important'), (None, '2024-06-28 15:24:18.000000', 'food', 'Kfc ', 475, 'Expense', 'Not Important'), (None, '2024-06-30 08:56:45.000000', 'others', 'From barath and shakur', 440, 'Income', 'Not Important'), (None, '2024-06-30 12:01:56.000000', 'others', 'haircut', 300, 'Expense', 'Not Important'), (None, '2024-07-01 07:55:10.000000', 'food', 'gum', 30, 'Expense', 'Not Important'), (None, '2024-07-02 00:16:03.000000', 'food', 'lunch', 500, 'Expense', 'Not Important'), (None, '2024-07-03 16:05:59.000000', 'others', 'magazine', 80, 'Expense', 'Not Important'), (None, '2024-07-06 15:58:00.000000', 'gift', 'Bharath birthday', 115, 'Expense', 'Not Important'), (None, '2024-07-09 01:36:05.000000', 'food', 'Lunch', 875, 'Expense', 'Not Important'), (None, '2024-07-11 12:23:28.000000', 'food', 'Lunch unlimited nv', 300, 'Expense', 'Not Important'), (None, '2024-07-11 16:42:24.000000', 'food', 'Bingo', 10, 'Expense', 'Not Important'), (None, '2024-07-16 17:57:38.000000', 'education', 'stationery', 120, 'Expense', 'Not Important'), (None, '2024-07-18 04:27:52.000000', 'entertainment', 'tickets concert', 2000, 'Expense', 'Not Important'), (None, '2024-07-18 21:06:45.000000', 'others', 'ice cream', 60, 'Expense', 'Not Important'), (None, '2024-07-18 21:44:06.000000', 'transportation', 'Rapido', 58, 'Expense', 'Not Important'), (None, '2024-07-19 15:33:59.000000', 'transportation', 'Rapido to pg', 44, 'Expense', 'Not Important'), (None, '2024-07-21 10:29:47.000000', 'social life', 'birthday gift', 500, 'Expense', 'Not Important'), (None, '2024-07-22 09:22:32.000000', 'food', 'Dairy milk', 10, 'Expense', 'Not Important'), (None, '2024-07-23 02:20:39.000000', 'food', 'fruit worth', 75, 'Expense', 'Not Important'), (None, '2024-07-23 07:52:09.000000', 'others', 'From ganesan', 40, 'Income', 'Not Important'), (None, '2024-07-23 14:33:28.000000', 'entertainment', 'course', 2500, 'Expense', 'Not Important'), (None, '2024-07-24 11:15:01.000000', 'food', 'groceries', 300, 'Expense', 'Not Important'), (None, '2024-07-26 02:51:26.000000', 'food', 'Snacks', 74, 'Expense', 'Not Important'), (None, '2024-07-26 17:20:57.000000', 'food', 'juice', 50, 'Expense', 'Not Important'), (None, '2024-07-28 11:40:55.000000', 'others', 'From dad', 1000, 'Income', 'Not Important'), (None, '2024-07-28 15:28:33.000000', 'social life', 'movie rental', 100, 'Expense', 'Not Important'), (None, '2024-07-31 02:41:39.000000', 'food', 'Side dishes', 165, 'Expense', 'Not Important'), (None, '2024-08-02 05:47:10.000000', 'others', 'pens', 75, 'Expense', 'Not Important'), (None, '2024-08-07 19:32:07.000000', 'others', 'From vicky', 200, 'Income', 'Not Important'), (None, '2024-08-08 03:04:42.000000', 'education', 'class', 600, 'Expense', 'Not Important'), (None, '2024-08-09 18:22:48.000000', 'food', 'Milk with bharath', 80, 'Expense', 'Not Important'), (None, '2024-08-15 06:50:43.000000', 'transportation', 'It better be worth it', 1300, 'Expense', 'Not Important'), (None, '2024-08-16 11:06:56.000000', 'food', 'Milk', 10, 'Expense', 'Not Important'), (None, '2024-08-19 14:35:33.000000', 'transportation', 'Metro', 30, 'Expense', 'Not Important'), (None, '2024-08-19 20:48:23.000000', 'food', 'Starbucks', 100, 'Expense', 'Not Important'), (None, '2024-08-22 19:25:11.000000', 'others', 'Vishnu 100 gowdham 25', 125, 'Income', 'Not Important'), (None, '2024-08-27 10:31:17.000000', 'household', 'family dinner', 500, 'Expense', 'Not Important'), (None, '2024-08-27 23:41:08.000000', 'food', 'water bottle', 100, 'Expense', 'Important'), (None, '2024-08-29 19:27:08.000000', 'shopping', 'Earphone', 399, 'Expense', 'Important'), (None, '2024-09-02 06:02:30.000000', 'food', 'Lunch with company', 75, 'Expense', 'Not Important'), (None, '2024-09-03 05:54:08.000000', 'others', 'magazine', 50, 'Expense', 'Not Important'), (None, '2024-09-03 06:54:01.000000', 'shopping', 'dress', 650, 'Expense', 'Not Important'), (None, '2024-09-05 00:45:01.000000', 'food', 'Cycle gap ', 120, 'Expense', 'Not Important'), (None, '2024-09-06 06:46:47.000000', 'shopping', 'clothes', 1000, 'Expense', 'Not Important'), (None, '2024-09-10 18:45:01.000000', 'others', 'headphones', 1000, 'Expense', 'Important'), (None, '2024-09-11 22:11:44.000000', 'food', 'coffee', 75, 'Expense', 'Not Important'), (None, '2024-09-13 22:09:04.000000', 'shopping', 'masks', 50, 'Expense', 'Not Important'), (None, '2024-09-15 05:03:58.000000', 'allowance', 'From dad', 1000, 'Income', 'Not Important'), (None, '2024-09-18 03:59:44.000000', 'food', 'Sent to vicky', 300, 'Expense', 'Not Important'), (None, '2024-09-18 16:32:02.000000', 'food', 'To rahul', 113, 'Expense', 'Not Important'), (None, '2024-09-19 15:03:23.000000', 'food', 'Lunch with stu', 150, 'Expense', 'Not Important'), (None, '2024-09-19 22:42:42.000000', 'food', 'Lunch', 40, 'Expense', 'Not Important'), (None, '2024-09-22 09:41:17.000000', 'food', 'groceries', 700, 'Expense', 'Not Important'), (None, '2024-09-27 06:26:54.000000', 'food', 'Friday snacks with preethi gang', 106, 'Expense', 'Not Important'), (None, '2024-10-01 13:04:08.000000', 'education', 'stationery', 150, 'Expense', 'Not Important'), (None, '2024-10-03 15:50:06.000000', 'entertainment', 'phone accessories', 180, 'Expense', 'Important'), (None, '2024-10-07 09:19:13.000000', 'food', 'dinner', 200, 'Expense', 'Not Important'), (None, '2024-10-08 19:40:04.000000', 'food', 'coffee', 150, 'Expense', 'Not Important'), (None, '2024-10-09 14:06:49.000000', 'education', 'books', 600, 'Expense', 'Not Important'), (None, '2024-10-15 15:35:38.000000', 'food', 'candy', 50, 'Expense', 'Not Important'), (None, '2024-10-15 18:32:22.000000', 'others', 'hotel stay', 1000, 'Expense', 'Not Important'), (None, '2024-10-17 16:27:43.000000', 'shopping', 'shirt', 800, 'Expense', 'Not Important'), (None, '2024-10-20 01:27:35.000000', 'shopping', 'clothes', 600, 'Expense', 'Not Important'), (None, '2024-10-28 01:53:20.000000', 'others', 'others', 3490, 'Expense', 'Not Important'), (None, '2024-10-31 20:31:50.000000', 'entertainment', 'museum ticket', 350, 'Expense', 'Not Important'), (None, '2024-11-02 20:38:18.000000', 'others', 'From vicky', 300, 'Income', 'Not Important'), (None, '2024-11-02 20:44:02.000000', 'others', 'bookmark', 40, 'Expense', 'Not Important')]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"select * from transactions;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7490419d-6289-41f1-a187-3a15126ad681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1b177db9140>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conn.execute(\"drop table transactions\")\n",
    "# conn.execute(\"delete from transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "39f98f3e-fc4d-4c9f-8d5a-433b45b9191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the Excel file\n",
    "file_path = 'Refined_Transaction_Importance_Classification.xlsx'  # Replace with your Excel file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Corrected transaction_entry function\n",
    "# def transaction_entry(amount, item, category, timestamp, type):\n",
    "#     cursor.execute(\"INSERT INTO transactions (amount, item, category, Timestamp, type) VALUES (?, ?, ?, ?, ?)\",\n",
    "#                    (amount, item, category, timestamp, type))\n",
    "#     conn.commit()\n",
    "\n",
    "# Insert all rows from the DataFrame into the database\n",
    "for _, row in df.iterrows():\n",
    "    transaction_entry(row['Amount'], row['Item'], row['Category'], row['Timestamp'], row['Type'], row['Importance'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fa1743da-de7e-48cd-8126-0b41dfb6a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "387ef4e2-8c68-469a-9392-b452ab955623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.close()\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb873d0-a669-4e41-b7df-bf5eab8889c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
